{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Two Sentence Horror Bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHGHMYYB4rgFPjKBOTDOed",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7fca2f98562141ecb7dbabfad7b12179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fcd5cb589aa648a9a9ffd895d64aaab1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce70fe14e7e84150832f7b17fe452bac",
              "IPY_MODEL_740dd6f27c474793b7aabadb2bcc60aa"
            ]
          }
        },
        "fcd5cb589aa648a9a9ffd895d64aaab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ce70fe14e7e84150832f7b17fe452bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a346b3d730f4f048611a31c909736e3",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4243663306d94fc98f8663ea0c440667"
          }
        },
        "740dd6f27c474793b7aabadb2bcc60aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_785fa26a95ab40b9a8d581726841e328",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:39&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_245cb62b84924221af208bca2024931f"
          }
        },
        "7a346b3d730f4f048611a31c909736e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4243663306d94fc98f8663ea0c440667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "785fa26a95ab40b9a8d581726841e328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "245cb62b84924221af208bca2024931f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "429b67d94a3645b5a4905e4039e1d605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb33aa5e5f1e4f648f48160fb705e9e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee895919b9164b31bc1a250ca72b841a",
              "IPY_MODEL_c86ca5c4531241deab2cdaf953953efe"
            ]
          }
        },
        "fb33aa5e5f1e4f648f48160fb705e9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ee895919b9164b31bc1a250ca72b841a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_246f557df7584fb9a8a7a4ecbd01f4b9",
            "_dom_classes": [],
            "description": "Epoch 0: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bc319d997ed4f2b893e4b902a28f564"
          }
        },
        "c86ca5c4531241deab2cdaf953953efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45e11f5dad9e45b397775b767f7aa23b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:24&lt;00:00,  2.05it/s, loss=3.72, v_num=7]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c49a3d2f1704e6f909f3a640f5e46fd"
          }
        },
        "246f557df7584fb9a8a7a4ecbd01f4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bc319d997ed4f2b893e4b902a28f564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45e11f5dad9e45b397775b767f7aa23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c49a3d2f1704e6f909f3a640f5e46fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342bb3376e394a4ab068f4f632044d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb2485748e4e4e8e8bf3a4f2de96ad3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_48f23795527c4641af1d4282eec067ac",
              "IPY_MODEL_61b381409f524441ac297797bd4b027b"
            ]
          }
        },
        "bb2485748e4e4e8e8bf3a4f2de96ad3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "48f23795527c4641af1d4282eec067ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4e7efda3f2e4dbdabb2b3576df9128c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b090cd169f94ffa92ea1ad24172e0e0"
          }
        },
        "61b381409f524441ac297797bd4b027b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_588451312e27435abb7bea87ebb48313",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:00&lt;00:00, 18.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc41218502dc4dee9cde186bd48b852b"
          }
        },
        "e4e7efda3f2e4dbdabb2b3576df9128c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b090cd169f94ffa92ea1ad24172e0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "588451312e27435abb7bea87ebb48313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc41218502dc4dee9cde186bd48b852b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfeucht/bart_horror/blob/main/Two_Sentence_Horror_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYrBvIWodW2I"
      },
      "source": [
        "# Two Sentence Horror Bot \n",
        "AI-generated two-sentence horror stories, using prompts from r/Showerthoughts. \n",
        "\n",
        "This file fine-tunes a pre-trained BART language model on a million top posts from [r/TwoSentenceHorror](https://www.reddit.com/r/TwoSentenceHorror/). It also randomly selects prompts from hot [r/Showerthoughts](https://www.reddit.com/r/Showerthoughts/) posts. \n",
        "\n",
        "# Examples\n",
        "\n",
        ">Whoever coined the saying, \"Money can't buy happiness\" never had to buy anti-depressants.\n",
        "If only I'd had the money.\n",
        "\n",
        ">Wood will probably be considered a luxury building material, like marble, when we colonise other star systems. It’s a shame that we can’t be considered a luxury building material, like marble, when we colonise other human systems.\n",
        "\n",
        ">Dig up someone who died yesterday and you're a criminal, dig up someone who died 1000 years ago and you're an archeologist.\n",
        "As I dig up the remains of someone who died 1000 years ago, I realize that I am not an archeologist.\n",
        "\n",
        ">“I wish it need not have happened in my time,” said Frodo. “I’m glad it’s not me,” said Frodo.\n",
        "\n",
        ">I was working in the lab late one night.\n",
        "I'm still working in the lab late at night.\n",
        "\n",
        "See [@BartHorror on Twitter](https://twitter.com/BartHorror) for more examples of this model in action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSrio5-SNeCR"
      },
      "source": [
        "#Setup (imports, installation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsbCuatktRkL",
        "outputId": "2bb844b3-7f78-466b-b847-eb17fc73a10f"
      },
      "source": [
        "!pip install -q pytorch-lightning\n",
        "!pip install -q transformers\n",
        "!pip install praw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.7/dist-packages (7.2.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.7/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: prawcore<3,>=2 in /usr/local/lib/python3.7/dist-packages (from praw) (2.0.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.7/dist-packages (from praw) (0.58.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.18->praw) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORx8g8CvlfKP"
      },
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import praw\n",
        "import argparse\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SfzY5upniEC"
      },
      "source": [
        "#First, collect and preprocess fine-tuning r/TwoSentenceHorror data from Reddit\n",
        "\n",
        "Use the [Python Reddit API Wrapper](https://praw.readthedocs.io/en/latest/getting_started/quick_start.html#read-only) to quickly extract training data from r/TwoSentenceHorror, getting the top million posts of all time. Can easily change the number of top posts we want to train on with `number_top_posts` variable. r/TwoSentenceHorror shouldn't have any empty selftext fields, but if you want to use this code for other subreddits make sure to include the line checking whether `submission.selftext` is an empty string to filter out images, links, and posts with only a title.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ViC-rHhnhSQ"
      },
      "source": [
        "raw_posts = pd.DataFrame(columns=['source', 'target'])\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"9UDziMBhY-pkjg\",\n",
        "    client_secret=\"iYKZ3yc5bFjBqVdgLuut43wRd6T63Q\",\n",
        "    user_agent=\"bart_horror by sfeucht\",\n",
        "    check_for_async=False\n",
        ")\n",
        "\n",
        "number_top_posts = 1000000\n",
        "for submission, rank in zip(reddit.subreddit('twosentencehorror').top(limit=number_top_posts), range(number_top_posts)):\n",
        "  if submission.selftext != '':\n",
        "    raw_posts.loc[rank] = [submission.title, submission.selftext]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cEo1CJ_MhgF"
      },
      "source": [
        "#Pytorch Lightning Model Setup\n",
        "\n",
        "Most of this code is taken directly from [this great tutorial](https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef) on fine-tuning BART by Neil Sinclair, as well as the [Pytorch Lightning Docs](https://pytorch-lightning.readthedocs.io/en/latest/starter/rapid_prototyping_templates.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aergjZerNlsk"
      },
      "source": [
        "# Function that takes a model as input (or part of a model) and freezes the layers for faster training, adapted from finetune.py\n",
        "def freeze_params(model):\n",
        "  for layer in model.parameters():\n",
        "    layer.requires_grade = False\n",
        "\n",
        "# Pytorch Lightning model module to hold the BART model \n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self, learning_rate, tokenizer, model, hparams):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.hparams = hparams\n",
        "\n",
        "        # freeze the positional embedding parameters and encoder for faster training \n",
        "        self.freeze_embeds()\n",
        "        freeze_params(self.model.get_encoder())\n",
        "\n",
        "    # freeze the positional embedding parameters of the model; adapted from finetune.py\n",
        "    def freeze_embeds(self):\n",
        "      freeze_params(self.model.model.shared)\n",
        "      for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "        freeze_params(d.embed_positions)\n",
        "        freeze_params(d.embed_tokens)\n",
        "    \n",
        "    # Do a forward pass through the model\n",
        "    def forward(self, input_ids, **kwargs):\n",
        "      return self.model(input_ids, **kwargs)\n",
        "\n",
        "    # Boilerplate from Pytorch Lightning rapid prototype templates, w/ custom learning_rate\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    # Train with the titles of posts as source and selftext as target\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Load the data into variables\n",
        "        src_ids, src_mask, tgt_ids = batch[0], batch[1], batch[2]\n",
        "\n",
        "        # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "        decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "\n",
        "        # Run the model and get the logits\n",
        "        outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "        lm_logits = outputs[0]\n",
        "        # Create the loss function, then calculate the loss on the un-shifted tokens\n",
        "        ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "        loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "        return {'loss':loss}\n",
        "\n",
        "    # To validate, do the exact same thing\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Load the data into variables\n",
        "        src_ids, src_mask, tgt_ids = batch[0], batch[1], batch[2]\n",
        "\n",
        "        # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "        decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "        \n",
        "        # Run the model and get the logits\n",
        "        outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "        lm_logits = outputs[0]\n",
        "        # Create the loss function, then calculate the loss on the un-shifted tokens\n",
        "        ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "        val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "        return {'loss': val_loss}\n",
        "\n",
        "    # Function to generate text from the trained model. Generate and then decode all the text generated\n",
        "    def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n",
        "      generated_ids = self.model.generate(\n",
        "          text[\"input_ids\"],\n",
        "          attention_mask=text[\"attention_mask\"],\n",
        "          use_cache=True,\n",
        "          decoder_start_token_id = self.tokenizer.pad_token_id,\n",
        "          num_beams = eval_beams,\n",
        "          max_length = max_len,\n",
        "          early_stopping = early_stopping\n",
        "      )\n",
        "      return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
        "  \n",
        "\n",
        "# Create a dataloading module to hold r/TwoSentenceHorror data as per the PyTorch Lightning Docs\n",
        "class HorrorDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, data_df, batch_size, num_examples = number_top_posts):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data_df = data_df\n",
        "    self.batch_size = batch_size\n",
        "    self.num_examples = num_examples\n",
        "  \n",
        "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
        "  def prepare_data(self):\n",
        "    self.data = self.data_df[:self.num_examples]\n",
        "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
        "\n",
        "  # encode the sentences using the tokenizer  \n",
        "  def setup(self, stage):\n",
        "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
        "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
        "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
        "\n",
        "  # Load the training, validation and test sets in TensorDataset objects\n",
        "  def train_dataloader(self):\n",
        "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
        "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
        "    return train_data\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
        "    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n",
        "    return val_data\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
        "    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n",
        "    return test_data\n",
        "\n",
        "# function that shifts input_ids one token to the right, and then wraps last non-pad token (usually <eos>)\n",
        "# taken directly from modeling_bart.py\n",
        "def shift_tokens_right(input_ids, pad_token_id):\n",
        "  prev_output_tokens = input_ids.clone()\n",
        "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
        "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
        "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
        "  return prev_output_tokens\n",
        "\n",
        "# function that tokenizes a bunch of source sentences for a training dataset\n",
        "# source_sentences and target_sentences correspond to 'source' and 'target' in training data\n",
        "# returns dict with structure {'input_ids':[], 'attention_mask':[], 'target_ids':[]}\n",
        "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  target_ids = []\n",
        "  tokenized_sentences = {}\n",
        "\n",
        "  # for each source sentence, tokenize and append to input_ids and attention_masks lists\n",
        "  for sentence in source_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # do the same for the target sentences, except save in list target_ids\n",
        "  for sentence in target_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "    target_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # flatten the three lists and return batch with all these as a dict\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "  target_ids = torch.cat(target_ids, dim = 0)\n",
        "\n",
        "  return {\"input_ids\": input_ids, \"attention_mask\": attention_masks, \"labels\": target_ids}\n",
        "\n",
        "# Function that noises a sentence by adding random <mask> tokens\n",
        "# sentence_ is the sentence to noise, percent_words is percent of words to replace (rounded up w/ math.ceil)\n",
        "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
        "  # Create a list item and copy\n",
        "  sentence_ = sentence_.split(' ')\n",
        "  sentence = sentence_.copy()\n",
        "  \n",
        "  num_words = math.ceil(len(sentence) * percent_words)\n",
        "  \n",
        "  # Create an array of tokens to sample from, can be any word in the sentence\n",
        "  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence))))\n",
        "  words_to_noise = random.sample(sample_tokens, num_words)\n",
        "  \n",
        "  # Swap out words, but not full stops\n",
        "  for pos in words_to_noise:\n",
        "      if sentence[pos] != '.':\n",
        "          sentence[pos] = replacement_token\n",
        "  \n",
        "  # Remove redundant spaces\n",
        "  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
        "  \n",
        "  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj2f5p-Twa-u"
      },
      "source": [
        "#Load in BART-base and insert data\n",
        "\n",
        "Using BART-base here due to computing constraints. But it still seems to work fairly well! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQr9X97fwenN"
      },
      "source": [
        "# Load the pre-trained model\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWydGvysMpjf"
      },
      "source": [
        "# set up hyperparameters, beam_size is 4\n",
        "hparams = argparse.Namespace()\n",
        "hparams.eval_beams = 4\n",
        "\n",
        "# Load the data into the model for training\n",
        "horror_data = HorrorDataModule(tokenizer, raw_posts, batch_size = 16, num_examples = 200000)\n",
        "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model, hparams = hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efCnEGKVHloJ"
      },
      "source": [
        "#Fine-tune BART on r/TwoSentenceHorror data\n",
        "\n",
        "The training time on this was short enough and the space I have on my Google Drive was scarce enough to make me decide to *not* save checkpoints for this model--that means the model does have to train every time, but it's not too expensive time-wise if you run it on a GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "7fca2f98562141ecb7dbabfad7b12179",
            "fcd5cb589aa648a9a9ffd895d64aaab1",
            "ce70fe14e7e84150832f7b17fe452bac",
            "740dd6f27c474793b7aabadb2bcc60aa",
            "7a346b3d730f4f048611a31c909736e3",
            "4243663306d94fc98f8663ea0c440667",
            "785fa26a95ab40b9a8d581726841e328",
            "245cb62b84924221af208bca2024931f",
            "429b67d94a3645b5a4905e4039e1d605",
            "fb33aa5e5f1e4f648f48160fb705e9e4",
            "ee895919b9164b31bc1a250ca72b841a",
            "c86ca5c4531241deab2cdaf953953efe",
            "246f557df7584fb9a8a7a4ecbd01f4b9",
            "7bc319d997ed4f2b893e4b902a28f564",
            "45e11f5dad9e45b397775b767f7aa23b",
            "1c49a3d2f1704e6f909f3a640f5e46fd",
            "342bb3376e394a4ab068f4f632044d4d",
            "bb2485748e4e4e8e8bf3a4f2de96ad3b",
            "48f23795527c4641af1d4282eec067ac",
            "61b381409f524441ac297797bd4b027b",
            "e4e7efda3f2e4dbdabb2b3576df9128c",
            "7b090cd169f94ffa92ea1ad24172e0e0",
            "588451312e27435abb7bea87ebb48313",
            "bc41218502dc4dee9cde186bd48b852b"
          ]
        },
        "id": "aGKmBYEVY2GZ",
        "outputId": "1ccc84cc-0100-4f34-dff0-db9c25eb1140"
      },
      "source": [
        "trainer = pl.Trainer(gpus = 1,\n",
        "                     max_epochs = 1,\n",
        "                     min_epochs = 1,\n",
        "                     auto_lr_find = True,\n",
        "                     progress_bar_refresh_rate = 500)\n",
        "trainer.fit(model, horror_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 139 M \n",
            "-------------------------------------------------------\n",
            "139 M     Trainable params\n",
            "0         Non-trainable params\n",
            "139 M     Total params\n",
            "557.682   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fca2f98562141ecb7dbabfad7b12179",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "429b67d94a3645b5a4905e4039e1d605",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "342bb3376e394a4ab068f4f632044d4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhicnbZjn3l4"
      },
      "source": [
        "#Collect first sentences from r/Showerthoughts\n",
        "\n",
        "BART can't come up with ideas out of thin air, so we have to provide it with a first sentence as a prompt for its two-sentence horror story. I found that taking posts from r/Showerthoughts was interesting, because they were about the right length and produced some entertaining results (in my opinion). \n",
        "\n",
        "We can take advantage of the high turnover of r/Showerthoughts by sampling from hot posts. While many posts there are good right out of the box, some consist of two or more sentences, like [this post](https://www.reddit.com/r/Showerthoughts/comments/mpdyxy/dragons_dont_really_breathe_fire_they_just_exhale/?utm_source=share&utm_medium=web2x&context=3):\n",
        "\n",
        "\n",
        "> **Dragons don't really breathe fire, they just exhale it.** That's like saying humans breathe carbon dioxide.\n",
        "\n",
        "Since these sentences are just meant to be jumping-off points for our model, I decided to split the sampled posts on punctuation marks and only feed the **first sentence** to the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3RFLUgiqsND"
      },
      "source": [
        "showerthoughts = []\n",
        "len_showerthoughts = 50 # won't necessarily get exactly this many, because of pinned posts\n",
        "\n",
        "# Sample some showerthoughts from hot posts. only take the first sentence, put a period at the end of it.\n",
        "for submission, rank in zip(reddit.subreddit('showerthoughts').hot(limit=len_showerthoughts), range(len_showerthoughts)):\n",
        "  # Check to make sure it's not a mod-stickied post\n",
        "  if not submission.stickied:\n",
        "    # split into sentences and append the first sentence\n",
        "    submission_sentences = re.split(r'[.!?;:]', submission.title)\n",
        "    showerthoughts.append(submission_sentences[0].strip() + '.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMKOcyliNcFQ"
      },
      "source": [
        "#Write some two-sentence horror stories!\n",
        "\n",
        "`generate_story()` is a function that generates a two-sentence horror story based on a single line as input. I noticed that the stories generated where the beginnings of the two sentences were the same were more boring, so if that happens we try again, this time masking the first token. \n",
        "\n",
        "`generate_stories_json()` is a function that takes in a list of prompts and then generates a horror story for each prompt, dumping the final list of stories into a json file. The json file consists of a list of `{'story':str, 'seen':bool}` tuples, where `seen=False` to make it easy to randomly sample and post to Twitter later on. If `shorten_for_twitter=True`, the model will keep generating stories until they fit within Twitter's 280 character limit, or just abandon it if it can't get anything short enough.\n",
        "\n",
        "Here, we hand over our list of r/showerthoughts posts as prompts for `generate_stories_json()` and then save as a file `twosentenceshower_currentdatetime.json`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7IHYXW1ZmCO"
      },
      "source": [
        "# function that returns a string containing a two-sentence horror story based on a single line as input. \n",
        "# first_sentence is the first half of our horror story, and model_ is the fine-tuned BART model. \n",
        "# I found that noise_percent of 0.3 seemed to generate entertaining results most of the time.\n",
        "def generate_story(first_sentence, model_, noise_percent = 0.3):\n",
        "  # Put the model on eval mode\n",
        "  model_.to(torch.device('cpu'))\n",
        "  model_.eval()\n",
        "\n",
        "  # prep output_story string and noise first_sentence\n",
        "  output_story = ''\n",
        "  output_story += first_sentence\n",
        "  prompt_tokenized = tokenizer(noise_sentence(first_sentence, noise_percent), max_length = 32, return_tensors = \"pt\", truncation = True)\n",
        "\n",
        "  # generate second_sentence from first_sentence. if\n",
        "  second_sentence = model.generate_text(prompt_tokenized, eval_beams = 5)[0].strip()\n",
        "\n",
        "  # if the first word of punchline is the same as first word of setup, try again but mask the first word of setup. \n",
        "  if second_sentence.split(' ')[0] == first_sentence.split(' ')[0]:\n",
        "    np_first_sentence = np.array(first_sentence.split(' '))\n",
        "    np_first_sentence[0] = '<mask>'\n",
        "    first_sentence_masked = ' '.join(np_first_sentence)\n",
        "    prompt_tokenized = tokenizer(noise_sentence(first_sentence_masked, noise_percent), max_length = 32, return_tensors = \"pt\", truncation = True)\n",
        "    second_sentence = model.generate_text(prompt_tokenized, eval_beams = 5)[0].strip()\n",
        "\n",
        "  # append to output and return it\n",
        "  output_story += '\\n\\n' \n",
        "  output_story += second_sentence\n",
        "  return output_story\n",
        "\n",
        "# function that takes in a list of first sentences and generates a two-sentence horror story for each one\n",
        "# returns a list of finalized stories as strings\n",
        "def generate_stories(prompt_list, shorten_for_twitter=False):\n",
        "  stories = []\n",
        "  for prompt in prompt_list:\n",
        "    story = generate_story(prompt, model)\n",
        "\n",
        "    if shorten_for_twitter: # try to keep it under 280 characters\n",
        "      safety_counter = 5 # try 5 times before giving up\n",
        "      while len(story) > 280 and safety_counter > 0:\n",
        "        story = generate_story(prompt, model)\n",
        "        safety_counter -= 1\n",
        "      if len(story) <= 280:\n",
        "        stories.append(story)\n",
        "\n",
        "    else: \n",
        "      stories.append(story)\n",
        "  \n",
        "  return stories\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwCmCXut4bAa",
        "outputId": "bf0b82d5-c9a5-48a9-c70a-2bef8ae29a2f"
      },
      "source": [
        "# Line of code to generate a single story from custom prompt\n",
        "# print(generate_story('If you stare at a squirrel long enough, it will die.', model))\n",
        "\n",
        "# Code to generate a bunch of stories from above collected showerthoughts\n",
        "twosentenceshower = generate_stories(showerthoughts, shorten_for_twitter = True)\n",
        "for story in twosentenceshower:\n",
        "  print(story + '\\n\\n')\n",
        "\n",
        "# Create dictionary and then dump it into json\n",
        "tss_json_list = [{'story': s, 'seen': False} for s in twosentenceshower]\n",
        "with open(datetime.now().strftime(\"twosentenceshower_%d_%m_%H%M.json\"), 'w') as f:\n",
        "  json.dump(tss_json_list, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<mask> likes to think that we are making order out of chaos, but in reality we are resisting the order of the universe because we find it unsatisfactory.\n",
            "<mask> coined the saying, \"Money can't buy happiness\" never had to buy anti-depressants.\n",
            "<mask> don't really breathe fire, they just exhale it.\n",
            "<mask> a bottle of pills says Don't Operate Heavy Machinery While Taking, initially your mind goes to bull dozers not cars.\n",
            "<mask> person born in the late 1900s sounds far older than a person born in 1997.\n",
            "<mask> you stare at a Squirrel long enough, it will die.\n",
            "<mask> humanity every colonizes other planets, physics students will have to memorize multiple gravitation constants.\n",
            "<mask> are positioned in a way to where “get out the car” brings on a lot of suspicious movements.\n",
            "<mask> adult telling a child to be careful when crossing the street is fairly normal, but an adult telling an adult to be careful crossing the street feels vaguely threatening.\n",
            "<mask> all the mysteries we face in life, none is quite as puzzling as why cling film sometimes clings so well, while at other times it just sits there without the barest hint of clingability.\n",
            "<mask> with two prosthetic legs can regulate their own height.\n",
            "<mask> probably a lot of GoPro video where the guy is doing a crazy dangerous stunt that we never see because they didn’t survive it.\n",
            "<mask> are often shocked that gamers spend 1,000€ on a gaming PC but they'll buy a 500€ console plus a 500€ laptop separately without blinking an eye.\n",
            "<mask> you do not allow yourself to be loved you can never love, like air in your lungs it is first received gladly and then given back the world.\n",
            "<mask> a chance you were the youngest person alive at one point, for like a split second maybe.\n",
            "<mask> NFTs are more than likely to rise and become a sought-out investment.\n",
            "<mask> easy for humans to move the chess pieces, but hard to know what move to make.\n",
            "Humanity likes to think that we are making order out of chaos, but in reality we are resisting the order of the universe because we find it unsatisfactory.\n",
            "The universe likes to think that we are making order out of the universe, but we find it unsatisfactory.\n",
            "\n",
            "A true friend is someone you can tell to stop being a fucking idiot with no hard feelings.\n",
            "It's a fucking shame, but it's hard to deny it.\n",
            "\n",
            "As annoying as it is, \"it depends\" is probably the most accurate answer to most questions.\n",
            "\"It depends\" is probably the most accurate answer to all of these questions.\n",
            "\n",
            "Whoever coined the saying, \"Money can't buy happiness\" never had to buy anti-depressants.\n",
            "It's the only thing I've ever had to buy.\n",
            "\n",
            "Wood will probably be considered a luxury building material, like marble, when we colonise other star systems.\n",
            "It will only be a matter of time before we find out what other people are doing with these systems.\n",
            "\n",
            "Employers want a two week notice before you leave but don’t give a two week notice before they terminate you.\n",
            "If you don’t want to leave, give me a week’s notice before you terminate.\n",
            "\n",
            "Dragons don't really breathe fire, they just exhale it.\n",
            "They don’t really see the fire, they just see the smoke.\n",
            "\n",
            "When a bottle of pills says Don't Operate Heavy Machinery While Taking, initially your mind goes to bull dozers not cars.\n",
            "It's a bit of a shock, but it's worth it, especially when it goes to bull dozers, not cars.\n",
            "\n",
            "A person born in the late 1900s sounds far older than a person born in 1997.\n",
            "If a person born in the late 1800s is born today, they are born in 1997.\n",
            "\n",
            "If you stare at a Squirrel long enough, it will die.\n",
            "If you look closely enough, you will see\n",
            "\n",
            "If humanity every colonizes other planets, physics students will have to memorize multiple gravitation constants.\n",
            "If humanity ever colonizes another planet, it will be with multiple gravitation constants.\n",
            "\n",
            "Seatbelts are positioned in a way to where “get out the car” brings on a lot of suspicious movements.\n",
            "“What’s going on?”\n",
            "\n",
            "Sinus allergies are our body's response to plants trying to MATE with us.\n",
            "It's like they're trying to MATE us.\n",
            "\n",
            "Jack Black would have made a great genie in Aladdin (live action).\n",
            "It would have made a great genie in the bottle.\n",
            "\n",
            "An adult telling a child to be careful when crossing the street is fairly normal, but an adult telling an adult to be careful crossing the street feels vaguely threatening.\n",
            "It's like an adult telling a child to be careful when crossing the street.\n",
            "\n",
            "There are some wow guilds that are older than the kids playing in them.\n",
            "There's no way to know that this is the first time I've been playing in the park.\n",
            "\n",
            "Sleeping next to your pet is cool, until you wake up with a soaking wet blanket and a dead goldfish.\n",
            "When you wake up in the morning, you’ll find a pile of goldfish.\n",
            "\n",
            "Blind people probably have stereotypes based on voice.\n",
            "We’ve all been there before.\n",
            "\n",
            "Sign making stores always have the ugliest signs advertising their business.\n",
            "It's the only way they can keep their business.\n",
            "\n",
            "When anteaters eat fire ants it’s like hot cheetos to them.\n",
            "It's like hot cheetos to me.\n",
            "\n",
            "Of all the mysteries we face in life, none is quite as puzzling as why cling film sometimes clings so well, while at other times it just sits there without the barest hint of clingability.\n",
            "Of all the mysteries in the world, none is as puzzling as this one.\n",
            "\n",
            "As someone who’s been both.\n",
            "It’s been both.\n",
            "\n",
            "You could have multiple personality disorder and not know it because the personalities are all basically the same.\n",
            "It’s all basically the same thing.\n",
            "\n",
            "One day one of those people who paint over old thrift store paintings is going to accidentally paint over something very valuable.\n",
            "It’s just a matter of time before I realize that I’m missing something very valuable.\n",
            "\n",
            "At some point in technology improvements, someone is gonna have serious burn injuries and will request a Darth Vader prosthetic suit.\n",
            "As long as I don’t get burn injuries, I’ll be fine.\n",
            "\n",
            "Just one house is some areas can easily cost more than the entire Louisiana Purchase.\n",
            "It’s easy to see why.\n",
            "\n",
            "It is surprising that Clarke Kent never got fired from his job when he constantly leaves work to save people's lives.\n",
            "It's not surprising that he never got fired from his job for trying to save people's lives.\n",
            "\n",
            "It's when you live alone that you learn the person who keeps taking your stuff is you.\n",
            "If you live alone, you learn that the only person who keeps taking your stuff is you.\n",
            "\n",
            "People with two prosthetic legs can regulate their own height.\n",
            "The only problem is that their legs don’t reach their full height.\n",
            "\n",
            "There’s probably a lot of GoPro video where the guy is doing a crazy dangerous stunt that we never see because they didn’t survive it.\n",
            "It’s probably safe to say that this is a very dangerous stunt that they’ll never see again because they didn’t survive it.\n",
            "\n",
            "People are often shocked that gamers spend 1,000€ on a gaming PC but they'll buy a 500€ console plus a 500€ laptop separately without blinking an eye.\n",
            "It’s often said that gamers can’t afford a gaming PC but a gaming console plus a 500€ laptop without blinking an eye.\n",
            "\n",
            "As children we see rain as an almost negative think.\n",
            "It's not as bad as you think.\n",
            "\n",
            "Mount Everest really is the most expensive cemetery.\n",
            "It’s the most beautiful place in the world.\n",
            "\n",
            "The inventor of the dog whistle probably didn't realize it at first.\n",
            "It's not that I didn't know it was a whistle, I just didn't realize it\n",
            "\n",
            "If you do not allow yourself to be loved you can never love, like air in your lungs it is first received gladly and then given back the world.\n",
            "If you do not allow yourself to be loved you will never love again, because in your lungs it is the only love you have ever given back.\n",
            "\n",
            "There’s a chance you were the youngest person alive at one point, for like a split second maybe.\n",
            "If I had a chance, I'd split up the family and split up, maybe.\n",
            "\n",
            "When you are left alone, you aren't scared you're alone, you're scared that you aren't.\n",
            "If you are scared, you're not alone.\n",
            "\n",
            "Pornographic NFTs are more than likely to rise and become a sought-out investment.\n",
            "The price of oil is more than likely to rise and become a more expensive investment.\n",
            "\n",
            "headphones are the \"fullscreen\" of audio.\n",
            "But it's not all that bad.\n",
            "\n",
            "Many people will publicly support beating children but no one will publicly support beating animals.\n",
            "I don't know why, but it's one of the first things I've heard about beating animals.\n",
            "\n",
            "Besides virgins, everyone else can be referred to as fuckers.\n",
            "It's not like everyone in the world can be referred to as fuckers.\n",
            "\n",
            "That delicious gas smell when your fill your car up.\n",
            "That's when you hear the car door slam.\n",
            "\n",
            "If we teleported into the future using a machine, we might teleport into space because the earth changes positions when rotating around the sun.\n",
            "When we teleport into space, the earth changes positions and the earth starts rotating around us.\n",
            "\n",
            "Hedge funds treat businesses the way the mafia treats restaurants in Goodfellas.\n",
            "It's the same way the mafia treats restaurants in Goodfellas.\n",
            "\n",
            "Feel lonely.\n",
            "advertisement\n",
            "\n",
            "Mrs Incredible’s real super-abilities were her incredible mom abilities because she survived the toddler years with a child that can run at supersonic speeds and another that can turn invisible at will.\n",
            "It's a real shame that her incredible mom died, but she survived.\n",
            "\n",
            "It's easy for humans to move the chess pieces, but hard to know what move to make.\n",
            "It’s easy to move the pieces, but hard to know what to make.\n",
            "\n",
            "Fingernails are an insult from evolution, reminding us we don't even have claws.\n",
            "It's an insult from evolution, but it's not even close to the claws.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZydV0xwRoSX",
        "outputId": "f69322eb-d18c-46da-afe5-ba4a6f83dd82"
      },
      "source": [
        "print(generate_story('I was working in the lab late one night.', model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I was working in the lab late one night.\n",
            "\n",
            "But I was working in the lab all night.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}